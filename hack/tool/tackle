#!/usr/bin/env python3

import argparse
import base64
import copy
from Crypto import Random
from Crypto.Cipher import AES
import datetime
import hashlib
import json
import os
import re
import requests
import shutil
import yaml

###############################################################################

parser = argparse.ArgumentParser(description='Konveyor Tackle maintenance tool.')
parser.add_argument('action', type=str, nargs='*',
                    help='One or more Tackle commands that should be executed, options: export export-tackle1 import clean clean-all')
parser.add_argument('-c','--config', type=str, help='A config file path (tackle-config.yml by default).',
                    nargs='?', default='./tackle-config.yml')
parser.add_argument('-d','--data-dir', type=str, help='Local Tackle data directory path (tackle-data by default).',
                    nargs='?', default='./tackle-data')
parser.add_argument('-v','--verbose', dest='verbose', action='store_const', const=True, default=False,
                    help='Print verbose output (including all API requests).')
parser.add_argument('-s','--skip-destination-check', dest='skipDestCheck', action='store_const', const=True, default=False,
                    help='Skip connection and data check of Tackle 2 destination.')
parser.add_argument('-w','--disable-ssl-warnings', dest='disableSslWarnings', action='store_const', const=True, default=False,
                    help='Do not display warnings during ssl check for api requests.')
parser.add_argument('-i','--ignore-import-errors', dest='ignoreImportErrors', action='store_const', const=True, default=False,
                    help='Skip to next item if an item fails load.')
parser.add_argument('-n','--no-auth', dest='noAuth', action='store_const', const=True, default=False,
                    help='Skip Keycloak token creation, use empty Auth token in Tackle API calls.')
parser.add_argument('-b','--skip-buckets', dest='skipBuckets', action='store_const', const=True, default=False,
                    help='Skip Tackle 2 Buckets content export.')
args = parser.parse_args()

###############################################################################

EXPORT_MANIFEST_FILENAME = "_manifest"
KNOWN_CRYPT_STRING = "tackle-cli-known-string-plaintext"

###############################################################################

def disableSSlWarnings(disableSslWarnings):
    if disableSslWarnings:
        requests.packages.urllib3.disable_warnings()

def ensureDataDir(dataDir):
    # Main dataDir
    if os.path.isdir(dataDir):
        debugPrint("Data directory already exists, using %s" % dataDir)
    else:
      debugPrint("Creating data directory at %s" % dataDir)
      os.mkdir(dataDir)
    # Buckets dump dataDir
    bucketsDir = "%s/buckets" % dataDir
    if os.path.isdir(bucketsDir):
        debugPrint("Buckets directory already exists, cleaning it: %s" % bucketsDir)
        shutil.rmtree(bucketsDir)
    debugPrint("Creating empty bucket directory at %s" % bucketsDir)
    os.mkdir(bucketsDir)

def checkConfig(expected_vars):
    for varKey in expected_vars:
        if os.environ.get(varKey) is None:
            print("ERROR: Missing required environment variable %s, define it first." % varKey)
            exit(1)

def loadConfig(path):
    debugPrint("Loading config from: %s" % path)
    try:
        data = open(path, 'r')
        return yaml.safe_load(data)
    except Exception as ex:
        print("ERROR reading config file %s: %s" % (path, ex))
        exit(1)

def debugPrint(str):
    if args.verbose:
        print(str)

def getKeycloakToken(host, username, password, client_id='tackle-ui', realm='tackle'):
    if args.noAuth:
        print("Skipping auth token creation for %s, using empty." % host)
        return ""

    print("Getting auth token from %s" % host)
    url  = "%s/auth/realms/%s/protocol/openid-connect/token" % (host, realm)
    data = {'username': username, 'password': password, 'client_id': client_id, 'grant_type': 'password'}

    r = requests.post(url, data=data, verify=False)
    if r.ok:
        respData = json.loads(r.text)
        debugPrint("Got access token: %s" % respData['access_token'])
        return respData['access_token']
    else:
        print("ERROR getting auth token from %s" % url)
        print(data, r)
        exit(1)

def apiJSON(url, token, data=None, method='GET', ignoreErrors=False):
    debugPrint("Querying: %s" % url)
    if method == 'DELETE':
        r = requests.delete(url, headers={"Authorization": "Bearer %s" % token, "Content-Type": "application/json"}, verify=False)
    elif method == 'POST':
        debugPrint("POST data: %s" % json.dumps(data))
        r = requests.post(url, data=json.dumps(data), headers={"Authorization": "Bearer %s" % token, "Content-Type": "application/json"}, verify=False)
    elif method == 'PATCH':
        debugPrint("PATCH data: %s" % json.dumps(data))
        r = requests.patch(url, data=json.dumps(data), headers={"Authorization": "Bearer %s" % token, "Content-Type": "application/json"}, verify=False)
    else: # GET
        r = requests.get(url, headers={"Authorization": "Bearer %s" % token, "Content-Type": "application/json"}, verify=False)

    if not r.ok:
        if ignoreErrors:
            debugPrint("Got status %d for %s, ignoring" % (r.status_code, url))
        else:
            print("ERROR: API request failed with status %d for %s" % (r.status_code, url))
            exit(1)

    if r.text is None or r.text ==  '':
        return

    debugPrint("Response: %s" % r.text)

    respData = json.loads(r.text)
    if '_embedded' in respData:
        debugPrint("Unwrapping Tackle1 JSON")
        return respData['_embedded'][url.rsplit('/')[-1].rsplit('?')[0]] # unwrap Tackle1 JSON response (e.g. _embedded -> application -> [{...}])
    else:
        return respData # raw return JSON (Tackle2, Pathfinder)

def apiRaw(url, token, data=None, method='GET', ignoreErrors=False):
    debugPrint("Querying: %s" % url)
    if method == 'DELETE':
        r = requests.delete(url, headers={"Authorization": "Bearer %s" % token}, verify=False)
    elif method == 'POST':
        debugPrint("POST data: %s" % json.dumps(data))
        r = requests.post(url, data=json.dumps(data), headers={"Authorization": "Bearer %s" % token}, verify=False)
    elif method == 'PATCH':
        debugPrint("PATCH data: %s" % json.dumps(data))
        r = requests.patch(url, data=json.dumps(data), headers={"Authorization": "Bearer %s" % token}, verify=False)
    else: # GET
        r = requests.get(url, headers={"Authorization": "Bearer %s" % token}, verify=False)

    if not r.ok:
        if ignoreErrors:
            debugPrint("Got status %d for %s, ignoring" % (r.status_code, url))
        else:
            print("ERROR: API request failed with status %d for %s" % (r.status_code, url))
            exit(1)

    return r.text

def apiFileGet(url, token, destinationPath, ignoreErrors=False):
    debugPrint("Getting file from %s" % url)
    # Get via streamed request
    with requests.get(url, headers={"Authorization": "Bearer %s" % token, "X-Directory": "archive"}, verify=False, stream=True) as resp:
        # Check for errors
        if not resp.ok:
            if ignoreErrors:
                debugPrint("Got status %d for get file %s, ignoring" % (resp.status_code, url))
            else:
                print("ERROR: File get API request failed with status %d for %s" % (resp.status_code, url))
                exit(1)
        # Store to local destination file
        with open(destinationPath, 'wb') as destFile:
            shutil.copyfileobj(resp.raw, destFile)
        destFile.close

    return destFile.name

def apiFilePost(url, token, filePath, ignoreErrors=False):
    debugPrint("Uploading file %s to %s" % (filePath, url))
    # Open local file
    with open(filePath, 'rb') as f:
        # Upload the content
        resp = requests.post(url, files={'file': f}, headers={"Authorization": "Bearer %s" % token, "X-Directory": "expand"}, verify=False)
        # Check for errors
        if not resp.ok:
            if ignoreErrors:
                debugPrint("Got status %d for post file %s, ignoring" % (resp.status_code, url))
            else:
                print("ERROR: File post API request failed with status %d for %s" % (resp.status_code, url))
                exit(1)
    return resp.text

def tackle2path(obj):
    if 'assessment' in obj:
        return "/hub/pathfinder/%s" % obj.replace("--", "/")    # Nested path decoding (e.g. assessments/assessment-risk)
    return "/hub/%s" % obj

def loadDump(path, fallback_value = []):
    try:
        data = open(path)
        return json.load(data)
    except Exception as ex:
        print("WARNING: Cannot open dump file %s, assuming empty data." % path)
        debugPrint(ex)
        return fallback_value


def saveJSON(path, jsonData):
    dumpFile = open(path + ".json", 'w')
    dumpFile.write(json.dumps(jsonData, indent=4, default=vars))
    dumpFile.close()

def cmdWanted(args, action):
    if action in args.action:
        return True
    else:
        return False

###############################################################################

class TackleTool:
    # TYPES order matters for import/upload to Tackle2
    TYPES = ['tagtypes', 'tags', 'jobfunctions', 'stakeholdergroups', 'stakeholders', 'businessservices', 'identities', 'applications', 'proxies', 'dependencies', 'assessments', 'reviews']
    NOT_IMPORTED_TYPES = ['taskgroups', 'tasks']
    TACKLE2_SEED_TYPES = ['tagtypes', 'tags', 'jobfunctions']

    def __init__(self, dataDir, tackle1Url, tackle1Token, tackle2Url, tackle2Token, encKey = ""):
        self.dataDir      = dataDir
        self.tackle1Url   = tackle1Url
        self.tackle1Token = tackle1Token
        self.tackle2Url   = tackle2Url
        self.tackle2Token = tackle2Token

        self.encKeyVerified = False
        if encKey != "":
            self.encKey = hashlib.sha256(encKey.encode('utf-8')).digest()

        # Dump data
        self.data         = dict()
        for t in self.TYPES:
            self.data[t] = []
        self.data['origin-tags'] = []   # temp storage for origin tags id remapping
        self.data['temp-buckets'] = []  # temp storage for bucket owner's refs during export
        # Existing resources in destination
        self.destData        = dict()
        for t in self.TYPES:
            self.destData[t] = dict()

    # Gather existing seeded objects from Tackle2
    def loadTackle2Seeds(self):
        # Tackle 2 TagTypes and Tags
        collection = apiJSON(tool.tackle2Url + "/hub/tagtypes", tool.tackle2Token)
        for tt2 in collection:
            tt  = Tackle2Object(tt2)
            tt.name = tt2['name']
            self.destData['tagtypes'][tt.name.lower()] = tt
            if tt2['tags']:
                for t2 in tt2['tags']:
                    tag             = Tackle2Object()
                    tag.id          = t2['id']
                    tag.name        = t2['name']
                    self.destData['tags'][tag.name.lower()] = tag

        # Tackle 2 JobFunctions
        collection = apiJSON(tool.tackle2Url + "/hub/jobfunctions", tool.tackle2Token)
        for jf2 in collection:
            jf              = Tackle2Object(jf2)
            jf.name         = jf2['name']
            self.destData['jobfunctions'][jf.name] = jf

    def findById(self, objType, id):
        # Search in data to be imported
        for obj in self.data[objType]:
            if obj.id == id:
                return obj
        # Raise error if still not found
        print("ERROR: %s record ID %d not found." % (objType, id))
        exit(1)

    # Gather Tackle 1.2 API objects and map seeded Tackle2 API objects
    def dumpTackle1(self):
        ### TAG TYPES & TAGS ###
        collection = apiJSON(self.tackle1Url + "/api/controls/tag-type", self.tackle1Token)
        for tt1 in collection:
            # Temp holder for tags
            tags = []
            # Prepare TagTypes's Tags
            for tag1 in tt1['tags']:
                tag             = Tackle2Object(tag1)
                tag.name        = tag1['name']
                # TagType is injected from tagType processing few lines below
                # Store Tag only if doesn't exist in Tackle2 destination already
                self.add('origin-tags', tag)   # tmp tags for merge with seed tags lookup
                if tag.name.lower() not in self.destData['tags']:
                    self.add('tags', tag)
                tags.append(tag)
            # Prepare TagType
            tt            = Tackle2Object(tt1)
            tt.name       = tt1['name']
            tt.colour     = tt1['colour']
            tt.rank       = tt1['rank']
            tt.username   = tt1['createUser']
            for tag in tags:
                tag.tagType = copy.deepcopy(tt)
            tt.tags = tags
            # Store only if doesn't exist in Tackle2 destination already
            if tt.name.lower() not in self.destData['tagtypes']:
                self.add('tagtypes', tt)

        ### APPLICATION ###
        collection = apiJSON(self.tackle1Url + "/api/application-inventory/application?page=0&size=10000", self.tackle1Token)
        for app1 in collection:
            # Temp holder for tags
            tags = []
            # Prepare Tags
            debugPrint(app1)
            if app1['tags']:
                for tagId in app1['tags']:
                    appTag = self.findById('origin-tags', int(tagId))
                    # Check if Tag exists in Tackle2 destination
                    if appTag.name.lower() in self.destData['tags']:
                        # Re-map to existing Tackle2 Tag
                        tags.append(self.destData['tags'][appTag.name.lower()])
                    else:
                        # Use imported Tag, creating a new one to cut association to Tag type
                        tag             = Tackle2Object()
                        tag.id          = appTag.id
                        tag.name        = appTag.name
                        tags.append(tag)
            # Prepare Application
            app                 = Tackle2Object(app1)
            app.name            = app1['name']
            app.description     = app1['description']
            app.tags            = tags
            if app1['businessService']:
                app.businessService = {'id':int(app1['businessService'])}
            else:
                print("Warning: Application %d %s has not businessService, which is required by Tackle2. Set it manually in %s/applications.json" % (app.id, app.name, self.dataDir))
            ### APPLICATION REVIEW ###
            if app1['review']:
                rev                 = Tackle2Object(app1['review'])
                rev.proposedAction      = app1['review']['proposedAction']
                rev.effortEstimate      = app1['review']['effortEstimate']
                rev.businessCriticality = app1['review']['businessCriticality']
                rev.workPriority        = app1['review']['workPriority']
                rev.comments            = app1['review']['comments']
                rev.application         = {'id': app.id, 'name': app.name}
                if app1['review']['copiedFromReviewId']:
                    rev.copiedFromReviewId  = app1['review']['copiedFromReviewId']
                self.add('reviews', rev)
            #app.repository      = app1['repository']   # Not part of 1.2 API 
            #app.binary          = app1['binary']
            #app.facts           = app1['facts']
            self.add('applications', app)

        ### DEPENDENCIES ###
        collection = apiJSON(self.tackle1Url + "/api/application-inventory/applications-dependency", self.tackle1Token)
        for dep1 in collection:
            # Prepare Dependency
            dep                 = Tackle2Object(dep1)
            dep.to              = {'id': dep1['to']['id'], 'name': dep1['to']['name']}
            setattr(dep, 'from', {'id': dep1['from']['id'], 'name': dep1['from']['name']})    # Cannot use "from" as an attribute name directly
            self.add('dependencies', dep)

        ### ASSESSMENTS & RISKS (per Application) ###
        for app in self.data['applications']:
            collection = apiJSON(self.tackle1Url + "/api/pathfinder/assessments?applicationId=%d" % app.id, self.tackle1Token)
            for assm1 in collection:
                # Prepare Assessment
                assm               = Tackle2Object()
                assm.id            = assm1['id']
                assm.applicationId = assm1['applicationId']
                assm.status        = assm1['status']
                # Prepare Assessment questions and answers
                asqa1 = apiJSON(self.tackle1Url + "/api/pathfinder/assessments/%d" % assm.id, self.tackle1Token)
                asqa               = Tackle2Object()
                asqa.id                = asqa1['id']
                asqa.applicationId     = asqa1['applicationId']
                asqa.status            = asqa1['status']
                asqa.stakeholders      = asqa1['stakeholders']
                asqa.stakeholderGroups = asqa1['stakeholderGroups']
                asqa.questionnaire     = asqa1['questionnaire']
                self.add('assessments', asqa)

            collection = apiJSON(self.tackle1Url + "/api/pathfinder/assessments/assessment-risk", self.tackle1Token, data=[{"applicationId": app.id}], method='POST')
            for assmr1 in collection:
                # Prepare Assessment Risk
                assmr               = Tackle2Object()
                assmr.assessmentId  = assmr1['assessmentId']
                assmr.applicationId = assmr1['applicationId']
                assmr.risk          = assmr1['risk']
                self.add('assessments--assessment-risk', assmr)

            collection = apiJSON(self.tackle1Url + "/api/pathfinder/assessments/confidence", self.tackle1Token, data=[{"applicationId": app.id}], method='POST')
            for conf1 in collection:
                # Prepare Confidence
                conf               = Tackle2Object()
                conf.assessmentId  = conf1['assessmentId']
                conf.applicationId = conf1['applicationId']
                conf.confidence    = conf1['confidence']
                self.add('assessments--confidence', conf)

        ### STAKEHOLDER ###
        collection = apiJSON(self.tackle1Url + "/api/controls/stakeholder", self.tackle1Token)
        for sh1 in collection:
            # Temp holder for stakeholder's groups
            shgs = []
            # Prepare StakeholderGroups
            for shg1 in sh1['stakeholderGroups']:
                shg             = Tackle2Object(shg1)
                shg.name        = shg1['name']
                shg.description = shg1['description']
                self.add('stakeholdergroups', shg)
                shgs.append(shg)
            # Prepare StakeHolder
            sh                   = Tackle2Object(sh1)
            sh.name              = sh1['displayName']
            sh.email             = sh1['email']
            sh.stakeholderGroups = shgs
            if sh1['jobFunction']:
                if sh1['jobFunction']['role'] in self.destData['jobfunctions']:
                    # Re-map to JobFunction existing in Tackle2 destination
                    sh.jobFunction = self.destData['jobfunctions'][sh1['jobFunction']['role']]
                else:
                    # Prepare new JobFunction
                    jf              = Tackle2Object(sh1['jobFunction'])
                    jf.name         = sh1['jobFunction']['role']
                    self.add('jobfunctions', jf)
                    sh.jobFunction = jf
            self.add('stakeholders', sh)
        
        ### STAKEHOLDER GROUPS ###
        collection = apiJSON(self.tackle1Url + "/api/controls/stakeholder-group", self.tackle1Token)
        for shg1 in collection:
            # Prepare StakeholderGroup
            shg             = Tackle2Object(shg1)
            shg.name        = shg1['name']
            shg.description = shg1['description']
            self.add('stakeholdergroups', shg)

        ### JOB FUNCTION ###
        collection = apiJSON(self.tackle1Url + "/api/controls/job-function", self.tackle1Token)
        for jf1 in collection:
            # Temp holder for stakeholders
            shs = []
            # Prepare JobFunction's Stakeholders
            for sh1 in jf1['stakeholders']:
                sh             = Tackle2Object(sh1)
                sh.name        = sh1['displayName']
                sh.email       = sh1['email']
                shs.append(sh)
            # Prepare JobFunction
            jf              = Tackle2Object(jf1)
            jf.name         = jf1['role']
            jf.stakeholders = shs
            # Store only if doesn't exist in Tackle2 destination already
            if jf.name not in self.destData['jobfunctions']:
                self.add('jobfunctions', jf)

        ### BUSINESS SERVICE ###
        collection = apiJSON(self.tackle1Url + "/api/controls/business-service", self.tackle1Token)
        for bs1 in collection:
            # Prepare JobFunction
            bs              = Tackle2Object(bs1)
            bs.name         = bs1['name']
            bs.description  = bs1['description']
            bs.owner        = bs1['owner']  # Stakeholder
            self.add('businessservices', bs)

    # Gather Tackle 2 API objects
    def dumpTackle2(self):
        ### TAG TYPES & TAGS ###
        collection = apiJSON(self.tackle2Url + "/hub/tagtypes", self.tackle2Token)
        for tt2 in collection:
            # Temp holder for tags
            tags = []
            # Prepare TagTypes's Tags
            for tag2 in tt2['tags']:
                tag             = Tackle2Object()
                tag.id          = tag2['id']
                tag.name        = tag2['name']
                # TagType is injected from tagType processing few lines below
                self.add('tags', tag)
                tags.append(tag)
            # Prepare TagType
            tt            = Tackle2Object()
            tt.id         = tt2['id']
            tt.name       = tt2['name']
            tt.colour     = tt2['colour']
            tt.rank       = tt2['rank']
            tt.username   = tt2['username']
            for tag in tags:
                tag.tagType = copy.deepcopy(tt)
            tt.tags = tags
            self.add('tagtypes', tt)

        ### APPLICATION ###
        collection = apiJSON(self.tackle2Url + "/hub/applications", self.tackle2Token)
        for app2 in collection:
            # Temp holder for tags
            tags = []
            # Prepare Tags
            debugPrint(app2)
            if app2['tags']:
                for tag2 in app2['tags']:
                    appTag = self.findById('tags', int(tag2['id']))
                    # Use imported Tag, creating a new one to cut association to Tag type
                    tag             = Tackle2Object()
                    tag.id          = appTag.id
                    tag.name        = appTag.name
                    tags.append(tag)
            # Prepare Application
            app                 = Tackle2Object(app2)
            app.name            = app2['name']
            app.description     = app2['description']
            app.tags            = tags
            app.businessService = app2['businessService']
            app.repository      = app2['repository'] 
            app.binary          = app2['binary']
            app.facts           = app2['facts']
            app.identities      = app2['identities']
            self.add('temp-buckets', {'owner': "applications/%s" % app.id})
            self.add('applications', app)

        ### DEPENDENCIES ###
        collection = apiJSON(self.tackle2Url + "/hub/dependencies", self.tackle2Token)
        for dep2 in collection:
            # Prepare Dependency
            dep                 = Tackle2Object(dep2)
            dep.to              = {'id': dep2['to']['id'], 'name': dep2['to']['name']}
            setattr(dep, 'from', {'id': dep2['from']['id'], 'name': dep2['from']['name']})    # Cannot use "from" as an attribute name directly
            self.add('dependencies', dep)


        ### APPLICATION REVIEW ###
        collection = apiJSON(self.tackle2Url + "/hub/reviews", self.tackle2Token)
        for rew2 in collection:
            rev                 = Tackle2Object(rew2)
            rev.proposedAction      = rew2['proposedAction']
            rev.effortEstimate      = rew2['effortEstimate']
            rev.businessCriticality = rew2['businessCriticality']
            rev.workPriority        = rew2['workPriority']
            rev.comments            = rew2['comments']
            rev.application         = rew2['application']
            self.add('reviews', rev)

        ### ASSESSMENTS & RISKS (per Application) ###
        for app in self.data['applications']:
            collection = apiJSON(self.tackle2Url + "/hub/pathfinder/assessments?applicationId=%d" % app.id, self.tackle2Token)
            for assm2 in collection:
                # Prepare Assessment
                assm               = Tackle2Object()
                assm.id            = assm2['id']
                assm.applicationId = assm2['applicationId']
                assm.status        = assm2['status']
                # Prepare Assessment questions and answers
                asqa2 = apiJSON(self.tackle2Url + "/hub/pathfinder/assessments/%d" % assm.id, self.tackle2Token)
                asqa               = Tackle2Object()
                asqa.id                = asqa2['id']
                asqa.applicationId     = asqa2['applicationId']
                asqa.status            = asqa2['status']
                asqa.stakeholders      = asqa2['stakeholders']
                asqa.stakeholderGroups = asqa2['stakeholderGroups']
                asqa.questionnaire     = asqa2['questionnaire']
                self.add('assessments', asqa)

        ### STAKEHOLDER ###
        collection = apiJSON(self.tackle2Url + "/hub/stakeholders", self.tackle2Token)
        for sh2 in collection:
            # Prepare StakeHolder
            sh             = Tackle2Object(sh2)
            sh.name        = sh2['name']
            sh.email       = sh2['email']
            sh.groups      = sh2['stakeholderGroups']
            sh.jobFunction = sh2['jobFunction']
            self.add('stakeholders', sh)

        ### STAKEHOLDER GROUPS ###
        collection = apiJSON(self.tackle2Url + "/hub/stakeholdergroups", self.tackle2Token)
        for shg2 in collection:
            # Prepare StakeholderGroup
            shg             = Tackle2Object(shg2)
            shg.name        = shg2['name']
            shg.description = shg2['description']
            self.add('stakeholdergroups', shg)

        ### JOB FUNCTION ###
        collection = apiJSON(self.tackle2Url + "/hub/jobfunctions", self.tackle2Token)
        for jf2 in collection:
            # Prepare JobFunction
            jf              = Tackle2Object(jf2)
            jf.name         = jf2['name']
            jf.stakeholders = jf2['stakeholders']
            self.add('jobfunctions', jf)

        ### BUSINESS SERVICE ###
        collection = apiJSON(self.tackle2Url + "/hub/businessservices", self.tackle2Token)
        for bs2 in collection:
            bs              = Tackle2Object(bs2)
            bs.name         = bs2['name']
            bs.description  = bs2['description']
            bs.owner        = bs2['owner']  # Stakeholder
            self.add('businessservices', bs)

        ### IDENTITY ###
        collection = apiJSON(self.tackle2Url + "/hub/identities?decrypted=1", self.tackle2Token)
        for id2 in collection:
            id             = Tackle2Object(id2)
            id.kind        = id2['kind']
            id.name        = id2['name']
            id.description = id2['description']
            id.user        = id2['user']
            id.password    = self.encrypt(id2['password'])
            id.key         = self.encrypt(id2['key'])
            id.settings    = self.encrypt(id2['settings'])
            self.add('identities', id)

        ### PROXY ###
        collection = apiJSON(self.tackle2Url + "/hub/proxies", self.tackle2Token)
        for pr2 in collection:
            pr          = Tackle2Object(pr2)
            pr.enabled  = pr2['enabled']
            pr.kind     = pr2['kind']
            pr.host     = pr2['host']
            pr.port     = pr2['port']
            pr.excluded = pr2['excluded']
            pr.identity = pr2['identity']
            self.add('proxies', pr)


    def dumpTackle2Buckets(self):
        bucketDir = "%s/buckets" % self.dataDir
        if not os.path.exists(bucketDir):
            os.mkdir(bucketDir)
        for bucket in self.data['temp-buckets']:
            debugPrint("Downloading bucket content for %s" % bucket['owner'])
            bucketFilename = bucket['owner'].replace("/", "--")
            apiFileGet(self.tackle2Url + "/hub/" + bucket['owner'] + "/bucket/", self.tackle2Token, bucketDir + "/%s.tar.gz" % bucketFilename)

    def uploadTackle2Buckets(self):
        bucketDir = "%s/buckets/" % self.dataDir
        if not os.path.exists(bucketDir):
            print("Warning: Buckets directory %s doesn't exist, skipping." % bucketDir)
            return
        for bucketArchive in os.listdir(bucketDir):
            ownerPath = bucketArchive.replace("--", "/").replace(".tar.gz", "")
            if os.path.getsize(bucketDir + bucketArchive) > 0:
                print("Uploading bucket archive for %s.." % ownerPath)
                apiFilePost(self.tackle2Url + "/hub/" + ownerPath + "/bucket/", self.tackle2Token, bucketDir + bucketArchive)
            else:
                debugPrint("Skipping empty bucket archive upload %s" % bucketArchive)

    def add(self, type, item):
        for existingItem in self.data[type]:
            if hasattr(item, 'id') and item.id == existingItem.id:  # assessment links objects don't have primary key id
                # The item is already present, skipping
                return
        self.data[type].append(item)

    def store(self):
        ensureDataDir(self.dataDir)
        for t in self.TYPES:
            saveJSON(os.path.join(self.dataDir, t), self.data[t])

    def uploadTackle2(self, ignoreErrors=False):
        # Hub objects
        for t in self.TYPES:
            # Skip separated imported objects
            if "assessment" in t:
                continue    # Pathfinder objects are imported separately

            dictCollection = loadDump(os.path.join(self.dataDir, t + '.json'))
            print("Uploading %s.." % t)
            for dictObj in dictCollection:
                # Decrypt Identity fields
                if "identities" in t:
                    dictObj['key'] = self.decrypt(dictObj['key'])
                    dictObj['password'] = self.decrypt(dictObj['password'])
                    dictObj['settings'] = self.decrypt(dictObj['settings'])

                debugPrint(dictObj)
                apiJSON(self.tackle2Url + tackle2path(t), self.tackle2Token, dictObj, method='POST', ignoreErrors=ignoreErrors)

        # Assessments / Pathfinder stuff import
        dictCollection = loadDump(os.path.join(self.dataDir, 'assessments.json'))
        print("Uploading assessments..")
        for assmnt1 in dictCollection:
            # Start the assessment
            assmnt2 = apiJSON(self.tackle2Url + tackle2path('assessments'), self.tackle2Token, data={"applicationId": assmnt1['applicationId']}, method='POST', ignoreErrors=ignoreErrors)
            # Populate the assessment questionnaire
            assmnt2 = apiJSON(self.tackle2Url + tackle2path("assessments/%d" % assmnt2['id']), self.tackle2Token, ignoreErrors=ignoreErrors)
            # Fill the assessment going through assessment to be imported and setting values to the newly created in Tackle2 (IDs changed, pairing with Order)
            for category in assmnt1['questionnaire']['categories']:
                debugPrint("Category %s" % category["order"])
                for question in category['questions']:
                    debugPrint("Question %s" % question["order"])
                    for option in question['options']:
                        debugPrint("Option %s" % option)
                        if option['checked'] == True:
                            # Find corresponding option in newly created assessment and check it
                            destCategory = next(cat for cat in assmnt2['questionnaire']['categories'] if cat['order'] == category['order'])
                            destQuestion = next(que for que in destCategory['questions'] if que['order'] == question['order'])
                            destOption = next(opt for opt in destQuestion['options'] if opt['order'] == option['order'])
                            debugPrint("Checking Tackle2 assessment option: %s" % destOption)
                            destOption['checked'] = True
            # Set remaining assessment attributes
            assmnt2['status']            = assmnt1['status']
            assmnt2['stakeholders']      = assmnt1['stakeholders']
            assmnt2['stakeholderGroups'] = assmnt1['stakeholderGroups']
            # Push the updated assessment
            apiJSON(self.tackle2Url + tackle2path("assessments/%d" % assmnt2['id']), self.tackle2Token, data=assmnt2, method='PATCH', ignoreErrors=ignoreErrors)

    def preImportCheck(self):
        for t in self.TYPES:
            # Pathfinder objects are dependent on Application which was checked before (and its check'd require iterating applications)
            if "assessment" in t:
                continue
            print("Checking %s in destination Tackle2.." % t)
            destCollection = apiJSON(self.tackle2Url + tackle2path(t), self.tackle2Token)
            localCollection = loadDump(os.path.join(self.dataDir, t + '.json'))
            for importObj in localCollection:
                # Pathfinder resources are dependent on Application, cheking it via applicationId
                if t == "applications":
                    # Check Application's Assessments first
                    asmnts = apiJSON(self.tackle2Url + "/hub/pathfinder/assessments?applicationId=%d" % importObj['id'], self.tackle2Token, ignoreErrors=True)
                    if len(asmnts) > 0:
                        print("ERROR: Pathfinder assessment for application ID %d already exists. Clean it before running the import with: tackle clean" % importObj['id'])
                        exit(1)
                for destObj in destCollection:
                    if importObj['id'] == destObj['id']:
                        print("ERROR: Resource %s/%d \"%s\" already exists in Tackle2 destination as \"%s\". Clean it before running the import with: tackle clean" % (t, importObj['id'], importObj['name'], destObj['name']))
                        exit(1)

    def cleanTackle2(self):
        self.TYPES.reverse()
        for t in self.TYPES:
            dictCollection = loadDump(os.path.join(self.dataDir, t + '.json'))
            for dictObj in dictCollection:
                if "assessment" in t:
                    continue
                # Pathfinder resources are dependent on Application
                if t == "applications":
                    # Delete related Application's Assessment resources first
                    collection = apiJSON(self.tackle2Url + "/hub/pathfinder/assessments?applicationId=%d" % dictObj['id'], self.tackle2Token, ignoreErrors=True)
                    for assm in collection:
                        print("Trying delete assessment %s for applicationId=%s" % (assm['id'], dictObj['id']))
                        apiJSON("%s/hub/pathfinder/assessments/%s" % (self.tackle2Url, assm['id']), self.tackle2Token, method='DELETE', ignoreErrors=True)
                # Hub resources
                print("Trying delete %s/%s" % (t, dictObj['id']))
                apiJSON("%s/hub/%s/%d" % (self.tackle2Url, t, dictObj['id']), self.tackle2Token, method='DELETE', ignoreErrors=True)

    def cleanAllTackle2(self):
        self.TYPES.reverse()
        for t in self.NOT_IMPORTED_TYPES + self.TYPES:
            # Pathfinder resources are dependent on Application, skip it
            if "assessment" in t:
                continue
            destCollection = apiJSON(self.tackle2Url + tackle2path(t), self.tackle2Token)
            for dictObj in destCollection:
                if t == "applications":
                    # Delete related Application's Assessment resources first
                    collection = apiJSON(self.tackle2Url + "/hub/pathfinder/assessments?applicationId=%d" % dictObj['id'], self.tackle2Token, ignoreErrors=True)
                    for assm in collection:
                        print("Deleting assessment %s for applicationId=%s" % (assm['id'], dictObj['id']))
                        apiJSON("%s/hub/pathfinder/assessments/%s" % (self.tackle2Url, assm['id']), self.tackle2Token, method='DELETE', ignoreErrors=True)
                # Hub resources
                print("Deleting %s/%s" % (t, dictObj['id']))
                apiJSON("%s/hub/%s/%d" % (self.tackle2Url, t, dictObj['id']), self.tackle2Token, method='DELETE', ignoreErrors=True)

    def encrypt(self, plain):
        if plain == "":
            return ""
        iv = Random.new().read(AES.block_size)
        cipher = AES.new(self.encKey, AES.MODE_CFB, iv)
        return base64.b64encode(iv + cipher.encrypt(plain)).decode('ascii')

    def decrypt(self, encrypted, verifyEncKey = True):
        # Check key from config file to be matching to key from export manifest to ensure decryption consistency
        if verifyEncKey and not self.encKeyVerified:
            if self.verifyManifestEncryptKey():
                self.encKeyVerified = True
            else:
                print("Decryption failure: inconsistent encryption_passphase in config, get more details with -v / --verbose option.")
                exit(1)
        # Decrypt the input
        encrypted_bytes = base64.b64decode(encrypted)
        if encrypted_bytes == b'':
            return ""
        iv = encrypted_bytes[:AES.block_size]
        cipher = AES.new(self.encKey, AES.MODE_CFB, iv)
        return cipher.decrypt(encrypted_bytes[AES.block_size:]).decode('utf-8')

    def saveManifest(self):
        mf = dict()
        mf['timestamp_utc'] = datetime.datetime.utcnow().isoformat()
        mf['command_options'] = args
        mf['known_string'] = KNOWN_CRYPT_STRING
        mf['crypted_known_string'] = self.encrypt(KNOWN_CRYPT_STRING)
        debugPrint("Saving manifest as %s" % EXPORT_MANIFEST_FILENAME)
        saveJSON(os.path.join(self.dataDir, EXPORT_MANIFEST_FILENAME), mf)

    def verifyManifestEncryptKey(self):
        debugPrint("Verifying manifest from %s" % EXPORT_MANIFEST_FILENAME)
        mf = loadDump(os.path.join(self.dataDir, EXPORT_MANIFEST_FILENAME + ".json"), {})
        if 'known_string' in mf and 'crypted_known_string' in mf and mf['crypted_known_string'] != "":
            if self.decrypt(mf['crypted_known_string'], False) == mf['known_string']:
                debugPrint("Encryption key check succeessful.")
                return True
            else:
                debugPrint("Encryption key check failure - incorrect passphase.")
                return False
        else:
            debugPrint("Encryption key check failure - empty or missing passphase.")
            return False


class Tackle2Object:
    def __init__(self, initAttrs = {}):
        if initAttrs:
            self.id         = initAttrs['id']
            self.createUser = initAttrs['createUser']
            self.updateUser = initAttrs['updateUser']

###############################################################################
# Disable SSL warnings if needed
disableSSlWarnings(args.disableSslWarnings)

# Load YAML config file (tackle-config.yml)
c = loadConfig(args.config)
cmdExecuted = False

# Tackle 1 export steps
if cmdWanted(args, "export-tackle1"):
    cmdExecuted = True
    # Gather Keycloak access tokens for Tackle1&2
    token1 = getKeycloakToken(c['tackle1']['url'], c['tackle1']['username'], c['tackle1']['password'])
    token2 = ""
    if not args.skipDestCheck:
        token2 = getKeycloakToken(c['url'], c['username'], c['password'])

    # Setup Tackle 1.2->2.0 data migration object
    tool = TackleTool(args.data_dir, c['tackle1']['url'], token1, c['url'], token2)

    # Run the export
    if not args.skipDestCheck:
        print("Loading seed objects from Tackle 2")
        tool.loadTackle2Seeds()
    print("Exporting Tackle 1.2 objects (this might take a while..)")
    tool.dumpTackle1()
    print("Writing JSON data files into %s" % args.data_dir)
    tool.store()
    print("Done. The data could be imported to Tackle 2 using command \"tackle import\"")

# Tackle 2 export steps
if cmdWanted(args, "export"):
    cmdExecuted = True
    # Gather Keycloak access tokens for Tackle2
    token2 = getKeycloakToken(c['url'], c['username'], c['password'])

    # Setup data migration object
    tool = TackleTool(args.data_dir, '', '', c['url'], token2, c['encryption_passphase'])

    # Run the export expecting clean destination
    print("Exporting Tackle 2 objects (this might take a while..)")
    tool.dumpTackle2()
    print("Writing JSON data files into %s" % args.data_dir)
    tool.store()
    tool.saveManifest()
    if args.skipBuckets:
        print("Skipping Buckets file content export.")
    else:
        print("Downloading Bucket content into %s/buckets" % args.data_dir)
        tool.dumpTackle2Buckets()
    print("Done. The data could be imported to another Tackle 2 using command \"tackle clean-all && tackle import\"")


# Tackle 2 import steps
if cmdWanted(args, "import"):
    cmdExecuted = True
    # Gather Keycloak access token for Tackle 2
    token2 = getKeycloakToken(c['url'], c['username'], c['password'])

    # Setup Tackle 1.2->2.0 data migration object
    tool = TackleTool(args.data_dir, '', '', c['url'], token2, c['encryption_passphase'])

    # Run the import
    print("Importing data to Tackle2")
    if not args.skipDestCheck:
        tool.preImportCheck()
    tool.uploadTackle2(ignoreErrors=args.ignoreImportErrors)

    if args.skipBuckets:
        print("Skipping Buckets content content import.")
    else:
        print("Uploading Bucket content into %s/buckets" % args.data_dir)
        tool.uploadTackle2Buckets()
    print("Done. Open your Tackle2 now!")

# Clean created objects in Tackle2
if cmdWanted(args, "clean"):
    cmdExecuted = True
    # Gather Keycloak access token for Tackle 2
    token2 = getKeycloakToken(c['url'], c['username'], c['password'])

    # Setup Tackle 1.2->2.0 data migration object
    tool = TackleTool(args.data_dir, '', '', c['url'], token2)

    # Run the cleanup
    print("Cleaning data created in Tackle2")
    tool.cleanTackle2()
    print("Done. Records from local JSON data files were removed from Tackle2 API.")

# Clean ALL objects in Tackle2
if cmdWanted(args, "clean-all"):
    cmdExecuted = True
    # Gather Keycloak access token for Tackle 2
    token2 = getKeycloakToken(c['url'], c['username'], c['password'])

    # Setup Tackle 1.2->2.0 data migration object
    tool = TackleTool(args.data_dir, '', '', c['url'], token2)

    # Run the cleanup including seeds
    print("Cleaning ALL data in Tackle2")
    tool.cleanAllTackle2()

# Print help if action was not specified
if not cmdExecuted:
    print("Unknown action, use tackle --help to see usage.")
    exit(1)

###############################################################################
